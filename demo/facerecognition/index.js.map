{
  "version": 3,
  "sources": ["index.ts"],
  "sourcesContent": ["/**\n * Human demo for browsers\n * @default Human Library\n * @summary <https://github.com/vladmandic/human>\n * @author <https://github.com/vladmandic>\n * @copyright <https://github.com/vladmandic>\n * @license MIT\n */\n\nimport { Human } from '../../dist/human.esm.js'; // equivalent of @vladmandic/Human\n\nconst humanConfig = { // user configuration for human, used to fine-tune behavior\n  modelBasePath: '../../models',\n  filter: { equalization: true }, // lets run with histogram equilizer\n  face: {\n    enabled: true,\n    detector: { rotation: true, return: true }, // return tensor is not really needed except to draw detected face\n    description: { enabled: true },\n    iris: { enabled: true }, // needed to determine gaze direction\n    emotion: { enabled: false }, // not needed\n    antispoof: { enabled: true }, // enable optional antispoof as well\n  },\n  body: { enabled: false },\n  hand: { enabled: false },\n  object: { enabled: false },\n  gesture: { enabled: true },\n};\n\nconst options = {\n  minConfidence: 0.6, // overal face confidence for box, face, gender, real\n  minSize: 224, // min input to face descriptor model before degradation\n  maxTime: 10000, // max time before giving up\n};\n\nconst human = new Human(humanConfig); // create instance of human with overrides from user configuration\n\nhuman.env['perfadd'] = false; // is performance data showing instant or total values\nhuman.draw.options.font = 'small-caps 18px \"Lato\"'; // set font used to draw labels when using draw methods\nhuman.draw.options.lineHeight = 20;\n\nconst dom = { // grab instances of dom objects so we dont have to look them up later\n  video: document.getElementById('video') as HTMLVideoElement,\n  canvas: document.getElementById('canvas') as HTMLCanvasElement,\n  log: document.getElementById('log') as HTMLPreElement,\n  fps: document.getElementById('fps') as HTMLPreElement,\n  status: document.getElementById('status') as HTMLPreElement,\n};\nconst timestamp = { detect: 0, draw: 0 }; // holds information used to calculate performance and possible memory leaks\nconst fps = { detect: 0, draw: 0 }; // holds calculated fps information for both detect and screen refresh\nlet startTime = 0;\n\nconst log = (...msg) => { // helper method to output messages\n  dom.log.innerText += msg.join(' ') + '\\n';\n  // eslint-disable-next-line no-console\n  console.log(...msg);\n};\nconst printFPS = (msg) => dom.fps.innerText = msg; // print status element\nconst printStatus = (msg) => dom.status.innerText = 'status: ' + JSON.stringify(msg).replace(/\"|{|}/g, '').replace(/,/g, ' | '); // print status element\n\nasync function webCam() { // initialize webcam\n  printFPS('starting webcam...');\n  // @ts-ignore resizeMode is not yet defined in tslib\n  const cameraOptions: MediaStreamConstraints = { audio: false, video: { facingMode: 'user', resizeMode: 'none', width: { ideal: document.body.clientWidth } } };\n  const stream: MediaStream = await navigator.mediaDevices.getUserMedia(cameraOptions);\n  const ready = new Promise((resolve) => { dom.video.onloadeddata = () => resolve(true); });\n  dom.video.srcObject = stream;\n  dom.video.play();\n  await ready;\n  dom.canvas.width = dom.video.videoWidth;\n  dom.canvas.height = dom.video.videoHeight;\n  const track: MediaStreamTrack = stream.getVideoTracks()[0];\n  const capabilities: MediaTrackCapabilities | string = track.getCapabilities ? track.getCapabilities() : '';\n  const settings: MediaTrackSettings | string = track.getSettings ? track.getSettings() : '';\n  const constraints: MediaTrackConstraints | string = track.getConstraints ? track.getConstraints() : '';\n  log('video:', dom.video.videoWidth, dom.video.videoHeight, track.label, { stream, track, settings, constraints, capabilities });\n  dom.canvas.onclick = () => { // pause when clicked on screen and resume on next click\n    if (dom.video.paused) dom.video.play();\n    else dom.video.pause();\n  };\n}\n\nasync function detectionLoop() { // main detection loop\n  if (!dom.video.paused) {\n    await human.detect(dom.video); // actual detection; were not capturing output in a local variable as it can also be reached via human.result\n    const now = human.now();\n    fps.detect = 1000 / (now - timestamp.detect);\n    timestamp.detect = now;\n    requestAnimationFrame(detectionLoop); // start new frame immediately\n  }\n}\n\nconst ok = { // must meet all rules\n  faceCount: false,\n  faceConfidence: false,\n  facingCenter: false,\n  eyesOpen: false,\n  blinkDetected: false,\n  faceSize: false,\n  antispoofCheck: false,\n  livenessCheck: false,\n  elapsedMs: 0,\n};\nconst allOk = () => ok.faceCount && ok.faceSize && ok.blinkDetected && ok.facingCenter && ok.faceConfidence && ok.antispoofCheck;\n\nasync function validationLoop(): Promise<typeof human.result.face> { // main screen refresh loop\n  const interpolated = await human.next(human.result); // smoothen result using last-known results\n  await human.draw.canvas(dom.video, dom.canvas); // draw canvas to screen\n  await human.draw.all(dom.canvas, interpolated); // draw labels, boxes, lines, etc.\n  const now = human.now();\n  fps.draw = 1000 / (now - timestamp.draw);\n  timestamp.draw = now;\n  printFPS(`fps: ${fps.detect.toFixed(1).padStart(5, ' ')} detect | ${fps.draw.toFixed(1).padStart(5, ' ')} draw`); // write status\n\n  const gestures: string[] = Object.values(human.result.gesture).map((gesture) => gesture.gesture); // flatten all gestures\n  ok.faceCount = human.result.face.length === 1; // must be exactly detected face\n  ok.eyesOpen = ok.eyesOpen || !(gestures.includes('blink left eye') || gestures.includes('blink right eye')); // blink validation is only ok once both eyes are open\n  ok.blinkDetected = ok.eyesOpen && ok.blinkDetected || gestures.includes('blink left eye') || gestures.includes('blink right eye'); // need to detect blink only once\n  ok.facingCenter = gestures.includes('facing center') && gestures.includes('looking center'); // must face camera and look at camera\n  ok.faceConfidence = (human.result.face[0].boxScore || 0) > options.minConfidence && (human.result.face[0].faceScore || 0) > options.minConfidence && (human.result.face[0].genderScore || 0) > options.minConfidence;\n  ok.antispoofCheck = (human.result.face[0].real || 0) > options.minConfidence;\n  ok.faceSize = human.result.face[0].box[2] >= options.minSize && human.result.face[0].box[3] >= options.minSize;\n\n  printStatus(ok);\n\n  if (allOk()) { // all criteria met\n    dom.video.pause();\n    return human.result.face;\n  } else {\n    human.tf.dispose(human.result.face[0].tensor); // results are not ok, so lets dispose tensor\n  }\n  if (ok.elapsedMs > options.maxTime) { // give up\n    dom.video.pause();\n    return human.result.face;\n  } else { // run again\n    ok.elapsedMs = Math.trunc(human.now() - startTime);\n    return new Promise((resolve) => {\n      setTimeout(async () => {\n        const res = await validationLoop(); // run validation loop until conditions are met\n        if (res) resolve(human.result.face); // recursive promise resolve\n      }, 30); // use to slow down refresh from max refresh rate to target of 30 fps\n    });\n  }\n}\n\nasync function detectFace(face) {\n  // draw face and dispose face tensor immediatey afterwards\n  dom.canvas.width = face.tensor.shape[2];\n  dom.canvas.height = face.tensor.shape[1];\n  dom.canvas.style.width = '';\n  human.tf.browser.toPixels(face.tensor, dom.canvas);\n  human.tf.dispose(face.tensor);\n\n  // run detection using human.match and use face.embedding as input descriptor\n  // tbd\n}\n\nasync function main() { // main entry point\n  log('human version:', human.version, '| tfjs version:', human.tf.version_core);\n  printFPS('loading...');\n  await human.load(); // preload all models\n  printFPS('initializing...');\n  await human.warmup(); // warmup function to initialize backend for future faster detection\n  await webCam(); // start webcam\n  await detectionLoop(); // start detection loop\n  startTime = human.now();\n  const face = await validationLoop(); // start validation loop\n  if (!allOk()) log('did not find valid input', face);\n  else {\n    log('found valid face', face);\n    await detectFace(face[0]);\n  }\n  dom.fps.style.display = 'none';\n}\n\nwindow.onload = main;\n"],
  "mappings": ";;;;;;;AASA;AATA,AAWA,IAAM,cAAc;AAAA,EAClB,eAAe;AAAA,EACf,QAAQ,EAAE,cAAc;AAAA,EACxB,MAAM;AAAA,IACJ,SAAS;AAAA,IACT,UAAU,EAAE,UAAU,MAAM,QAAQ;AAAA,IACpC,aAAa,EAAE,SAAS;AAAA,IACxB,MAAM,EAAE,SAAS;AAAA,IACjB,SAAS,EAAE,SAAS;AAAA,IACpB,WAAW,EAAE,SAAS;AAAA;AAAA,EAExB,MAAM,EAAE,SAAS;AAAA,EACjB,MAAM,EAAE,SAAS;AAAA,EACjB,QAAQ,EAAE,SAAS;AAAA,EACnB,SAAS,EAAE,SAAS;AAAA;AAGtB,IAAM,UAAU;AAAA,EACd,eAAe;AAAA,EACf,SAAS;AAAA,EACT,SAAS;AAAA;AAGX,IAAM,QAAQ,IAAI,MAAM;AAExB,MAAM,IAAI,aAAa;AACvB,MAAM,KAAK,QAAQ,OAAO;AAC1B,MAAM,KAAK,QAAQ,aAAa;AAEhC,IAAM,MAAM;AAAA,EACV,OAAO,SAAS,eAAe;AAAA,EAC/B,QAAQ,SAAS,eAAe;AAAA,EAChC,KAAK,SAAS,eAAe;AAAA,EAC7B,KAAK,SAAS,eAAe;AAAA,EAC7B,QAAQ,SAAS,eAAe;AAAA;AAElC,IAAM,YAAY,EAAE,QAAQ,GAAG,MAAM;AACrC,IAAM,MAAM,EAAE,QAAQ,GAAG,MAAM;AAC/B,IAAI,YAAY;AAEhB,IAAM,MAAM,IAAI,QAAQ;AACtB,MAAI,IAAI,aAAa,IAAI,KAAK,OAAO;AAErC,UAAQ,IAAI,GAAG;AAAA;AAEjB,IAAM,WAAW,CAAC,QAAQ,IAAI,IAAI,YAAY;AAC9C,IAAM,cAAc,CAAC,QAAQ,IAAI,OAAO,YAAY,aAAa,KAAK,UAAU,KAAK,QAAQ,UAAU,IAAI,QAAQ,MAAM;AAEzH,wBAAwB;AACtB,WAAS;AAET,QAAM,gBAAwC,EAAE,OAAO,OAAO,OAAO,EAAE,YAAY,QAAQ,YAAY,QAAQ,OAAO,EAAE,OAAO,SAAS,KAAK;AAC7I,QAAM,SAAsB,MAAM,UAAU,aAAa,aAAa;AACtE,QAAM,QAAQ,IAAI,QAAQ,CAAC,YAAY;AAAE,QAAI,MAAM,eAAe,MAAM,QAAQ;AAAA;AAChF,MAAI,MAAM,YAAY;AACtB,MAAI,MAAM;AACV,QAAM;AACN,MAAI,OAAO,QAAQ,IAAI,MAAM;AAC7B,MAAI,OAAO,SAAS,IAAI,MAAM;AAC9B,QAAM,QAA0B,OAAO,iBAAiB;AACxD,QAAM,eAAgD,MAAM,kBAAkB,MAAM,oBAAoB;AACxG,QAAM,WAAwC,MAAM,cAAc,MAAM,gBAAgB;AACxF,QAAM,cAA8C,MAAM,iBAAiB,MAAM,mBAAmB;AACpG,MAAI,UAAU,IAAI,MAAM,YAAY,IAAI,MAAM,aAAa,MAAM,OAAO,EAAE,QAAQ,OAAO,UAAU,aAAa;AAChH,MAAI,OAAO,UAAU,MAAM;AACzB,QAAI,IAAI,MAAM;AAAQ,UAAI,MAAM;AAAA;AAC3B,UAAI,MAAM;AAAA;AAAA;AAInB,+BAA+B;AAC7B,MAAI,CAAC,IAAI,MAAM,QAAQ;AACrB,UAAM,MAAM,OAAO,IAAI;AACvB,UAAM,MAAM,MAAM;AAClB,QAAI,SAAS,MAAQ,OAAM,UAAU;AACrC,cAAU,SAAS;AACnB,0BAAsB;AAAA;AAAA;AAI1B,IAAM,KAAK;AAAA,EACT,WAAW;AAAA,EACX,gBAAgB;AAAA,EAChB,cAAc;AAAA,EACd,UAAU;AAAA,EACV,eAAe;AAAA,EACf,UAAU;AAAA,EACV,gBAAgB;AAAA,EAChB,eAAe;AAAA,EACf,WAAW;AAAA;AAEb,IAAM,QAAQ,MAAM,GAAG,aAAa,GAAG,YAAY,GAAG,iBAAiB,GAAG,gBAAgB,GAAG,kBAAkB,GAAG;AAElH,gCAAmE;AACjE,QAAM,eAAe,MAAM,MAAM,KAAK,MAAM;AAC5C,QAAM,MAAM,KAAK,OAAO,IAAI,OAAO,IAAI;AACvC,QAAM,MAAM,KAAK,IAAI,IAAI,QAAQ;AACjC,QAAM,MAAM,MAAM;AAClB,MAAI,OAAO,MAAQ,OAAM,UAAU;AACnC,YAAU,OAAO;AACjB,WAAS,QAAQ,IAAI,OAAO,QAAQ,GAAG,SAAS,GAAG,iBAAiB,IAAI,KAAK,QAAQ,GAAG,SAAS,GAAG;AAEpG,QAAM,WAAqB,OAAO,OAAO,MAAM,OAAO,SAAS,IAAI,CAAC,YAAY,QAAQ;AACxF,KAAG,YAAY,MAAM,OAAO,KAAK,WAAW;AAC5C,KAAG,WAAW,GAAG,YAAY,CAAE,UAAS,SAAS,qBAAqB,SAAS,SAAS;AACxF,KAAG,gBAAgB,GAAG,YAAY,GAAG,iBAAiB,SAAS,SAAS,qBAAqB,SAAS,SAAS;AAC/G,KAAG,eAAe,SAAS,SAAS,oBAAoB,SAAS,SAAS;AAC1E,KAAG,iBAAkB,OAAM,OAAO,KAAK,GAAG,YAAY,KAAK,QAAQ,iBAAkB,OAAM,OAAO,KAAK,GAAG,aAAa,KAAK,QAAQ,iBAAkB,OAAM,OAAO,KAAK,GAAG,eAAe,KAAK,QAAQ;AACvM,KAAG,iBAAkB,OAAM,OAAO,KAAK,GAAG,QAAQ,KAAK,QAAQ;AAC/D,KAAG,WAAW,MAAM,OAAO,KAAK,GAAG,IAAI,MAAM,QAAQ,WAAW,MAAM,OAAO,KAAK,GAAG,IAAI,MAAM,QAAQ;AAEvG,cAAY;AAEZ,MAAI,SAAS;AACX,QAAI,MAAM;AACV,WAAO,MAAM,OAAO;AAAA,SACf;AACL,UAAM,GAAG,QAAQ,MAAM,OAAO,KAAK,GAAG;AAAA;AAExC,MAAI,GAAG,YAAY,QAAQ,SAAS;AAClC,QAAI,MAAM;AACV,WAAO,MAAM,OAAO;AAAA,SACf;AACL,OAAG,YAAY,KAAK,MAAM,MAAM,QAAQ;AACxC,WAAO,IAAI,QAAQ,CAAC,YAAY;AAC9B,iBAAW,YAAY;AACrB,cAAM,MAAM,MAAM;AAClB,YAAI;AAAK,kBAAQ,MAAM,OAAO;AAAA,SAC7B;AAAA;AAAA;AAAA;AAKT,0BAA0B,MAAM;AAE9B,MAAI,OAAO,QAAQ,KAAK,OAAO,MAAM;AACrC,MAAI,OAAO,SAAS,KAAK,OAAO,MAAM;AACtC,MAAI,OAAO,MAAM,QAAQ;AACzB,QAAM,GAAG,QAAQ,SAAS,KAAK,QAAQ,IAAI;AAC3C,QAAM,GAAG,QAAQ,KAAK;AAAA;AAMxB,sBAAsB;AACpB,MAAI,kBAAkB,MAAM,SAAS,mBAAmB,MAAM,GAAG;AACjE,WAAS;AACT,QAAM,MAAM;AACZ,WAAS;AACT,QAAM,MAAM;AACZ,QAAM;AACN,QAAM;AACN,cAAY,MAAM;AAClB,QAAM,OAAO,MAAM;AACnB,MAAI,CAAC;AAAS,QAAI,4BAA4B;AAAA,OACzC;AACH,QAAI,oBAAoB;AACxB,UAAM,WAAW,KAAK;AAAA;AAExB,MAAI,IAAI,MAAM,UAAU;AAAA;AAG1B,OAAO,SAAS;",
  "names": []
}
